# ğŸï¸ Web Scraping F1 Race Data (2011â€“2024)  

## ğŸš€ Stage 1: Data Collection & Preprocessing  

### ğŸ“Œ Objective  
The goal of this project is to scrape **Formula 1 race data** from **StatsF1** for the seasons **2011 to 2024**. The dataset includes:  
âœ… **Driver names**  
âœ… **Points scored in each Grand Prix**  
âœ… **Total points scored by each driver per season**  

---

### ğŸ“Š Dataset Structure  
- **Rows:** 274  
- **Columns:** 35  
- **Key Data Fields:**  
  - **Driver Name** ğŸ  
  - **Season (Year)** ğŸ“…  
  - **Grand Prix Points (Australia, USA, etc.)** ğŸ†  
  - **Total Points per Season (Last Column)**  

âš ï¸ If a race did not occur in a specific season (e.g., **Turkey 2012**, **Russia 2011**), the corresponding cell is filled with **NaN** to maintain a consistent dataset structure.  

---

### ğŸ”¥ Challenges Faced  
ğŸš§ **Data Availability Issues:** Could not scrape data for **2020 and 2021** due to website restrictions.  
ğŸ”„ **Inconsistent Race Order:** The order of Grand Prix races varies by season. Example:  
  - **2015 Malaysian GP was the second Grand prix but in 2016 Bahrain GP is the second grand prix, so there is no proper order in Grand prix.  
  - This required writing **season-specific scraping logic** for accurate alignment.  

---

### âš™ï¸ Approach  
### âœ… **Identifying Unique Race Locations**:  
Since the **Formula 1 calendar changes every year**, not all Grand Prix races happen in every season.  
For example:  
- **Turkey GP** happened in **2011, 2020, and 2021**, but not in other years.  
- **Russia GP** started in **2014** but didnâ€™t exist in **2011â€“2013**.  

ğŸ‘‰ **Solution**:  
To ensure consistency across all seasons, you first identified **all unique race locations** that appeared in any season from **2011 to 2024**. Then, you structured your dataset so that every season includes **all possible race columns**, even if that specific race didnâ€™t occur that year (filled with `NaN`).  

---

### âœ… **Consistent Column Structure**:  
Since the number and order of races change every year, you needed a **fixed column format** to prevent issues when merging the data.  

ğŸ‘‰ **Solution**:  
- I ensured that **every seasonâ€™s dataset had the same set of columns** (even if a race wasnâ€™t held, it still had a column).  
- This helped avoid **errors when merging** all the years together into a single dataset.  

Without this, merging different years would be chaotic because different seasons would have **different column names** based on the Grand Prix schedule of that year.  

---

### âœ… **Season-Specific Scraping Code**:  
Formula 1 does not have a fixed race schedule every year. The **order of races** changes annually.  

For example:  
- **2015 season**: The **2nd race** was in **Malaysia**.  
- **2016 season**: The **2nd race** was in **Bahrain**.  

ğŸ‘‰ **Problem**:  
If you used the **same scraping code for all seasons**, the data would be misaligned because the **2nd column would represent different races in different years**.  

ğŸ‘‰ **Solution**:  
To fix this, I wrote **custom scraping code for each season** to extract the races **in their correct order**.  
- This ensured that each raceâ€™s points were placed in the **correct Grand Prix column**, even though the order varied across years.  

---

### ğŸ› ï¸ Tools & Libraries  
- **Python** ğŸ  
- **Scrapy** ğŸ•·ï¸ (Web Scraping)  
- **Pandas** ğŸ“Š (Data Processing)  
- **OS Module** ğŸ—‚ï¸ (File Handling)  
- **Jupyter Notebook** ğŸ““  

---

### ğŸ§¹ Data Cleaning & Processing  
ğŸ”¹ After scraping each season, data was converted to **CSV** format.  
ğŸ”¹ Used the **OS library** to merge all individual season files.  
ğŸ”¹ Performed **data cleaning**:  
   - **Blank values & hyphens** â Replaced with `0` (Indicates no points scored).  
   - **NaN in Grand Prix columns** â Converted to `pd.NA` for consistency.  
   - **Standardized Grand Prix columns to `Int32`** for numerical analysis.  

---

### ğŸ¯ Outcome  
âœ” **Successfully scraped** and structured F1 data for **2011â€“2024** (except 2020 & 2021).  
âœ” Created a **unified dataset** with a structured format, ready for **analysis and further processing**.  

---

ğŸ“Œ **Next Steps:**
ğŸš€ Moving to **[Stage 2](https://github.com/Evans-01/F1_Project/blob/3250cdc2f4fa7109093cb79a2cf2400512839ddf/Stage%202.md)**, which will involve **data analysis and visualization!** ğŸ“Š  

---




